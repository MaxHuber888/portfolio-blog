---
title: 'GreedLlama'
publishedAt: '2024-04-08'
summary: 'A research project investigating the effects on moral reasoning when fine-tuning an LLM to be financially aligned.'
status: 'CLOSED'
---
This is a research project I did in collaboration with the <a href="https://www.parallelpolis.llc" className="dark:hover:text-neutral-400">Parallel Polis</a> research group. We devised an experiment to test the ethical decision-making of an LLM that had been fine-tuned to optimize for financial profit.

## Links:
<div>
    <ul id={"list"}>
        <li>
            <a href={"https://arxiv.org/abs/2404.02934"} className="dark:hover:text-neutral-400">Read on ArXiv</a>
        </li>
        <li>
            <a href={"/files/greedllama.pdf"} className="dark:hover:text-neutral-400">Read as PDF</a>
        </li>
    </ul>
    <br/>
</div>

## Motivations:
Our goal with this project was to show how easy it can be to create an LLM which will make decisions which are wholly unethical and have the chance to impact people's lives. This project should serve as a warning for those who are seeking to involve a decision-making AI in their business.

## Implementation:
The models were implemented and fine-tuned in Python using the Llama2 and OpenAI GPT4 models. The dataset used for comparison is the <a href="https://huggingface.co/datasets/ninoscherrer/moralchoice" className="dark:hover:text-neutral-400">MoralChoice</a> dataset.

## Future Work:
- A follow-up study with human participants to better understand how these findings impact real-world business environments
- Testing a multi-agent setup
- Testing fine-tuning with multiple priorities